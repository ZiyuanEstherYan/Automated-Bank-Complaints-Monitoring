---
title: "unstructured data"
author: "Kexin"
date: "1/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(readxl)
library(tidyverse)
library(tidytext)
library(scales)
library(radiant)
library(topicmodels)
library(SnowballC)
library(keras)
library(tm)
library(yardstick)
#library(LDAvis)
#library(textstem)
```

##### Topic model on total monetary complaints and one product: 
#### Start from this

```{r}
#import data
data_total_monetary=read_csv('data/Monetary Complaints total data.csv')
credit_card=read_csv('../data/credit card total data.csv')
```

# Credit card: Create a balanced sample

```{r}
set.seed(1234)
credit_card=credit_card %>% 
  mutate(important=(ifelse(`Company response to consumer`=='Closed with monetary relief',1,0))) %>% 
  group_by(important) %>% 
  sample_n(7186)
table(credit_card$important)
```

```{r}
maxWords <- 8000  #only use the top 5000 words 
tokenizer <- text_tokenizer(num_words = maxWords) %>%
  fit_text_tokenizer(credit_card$`Consumer complaint narrative`)

sequences <- texts_to_sequences(tokenizer, credit_card$`Consumer complaint narrative`)

word_index <- tokenizer$word_index

nReviews <- nrow(credit_card)
nReviews
```

```{r}
## one-hot code tokens and reshuffle data
x <- sequences_to_matrix(tokenizer, sequences, mode = c("binary"))
y <- as.numeric(credit_card$important)
set.seed(1234)
shuffIndex <- sample(1:nReviews) 
shuffIndex[1:5]
nTrain <- floor(nReviews * 0.7)
nTrain

trainIndex <- shuffIndex[1:nTrain]
trainIndex[1:5]

testIndex <- shuffIndex[(nTrain+1):nReviews]
testIndex[1:5]

xTrain <- x[trainIndex,]
yTrain <- y[trainIndex]

xTest <- x[testIndex,]
yTest <- y[testIndex]
```

```{r}
model <- keras_model_sequential() %>% 
  layer_dense(units = 128, activation = "relu", input_shape = c(maxWords)) %>% 
  layer_dense(units = 128, activation = "relu") %>% 
  layer_dense(units = 128, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")
model
```

```{r}
model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)
```

```{r}
historyT <- model %>% fit(
  xTrain,
  yTrain,
  epochs = 20,
  batch_size = 256,
  validation_split = 0.2
)
```

```{r}
## re-train at optimized epoch
theEpoch=which.min(historyT$metrics$val_loss)

model <- keras_model_sequential() %>% 
  layer_dense(units = 128, activation = "relu", input_shape = c(maxWords)) %>% 
  layer_dense(units = 128, activation = "relu") %>% 
  layer_dense(units = 128, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

history <- model %>% fit(xTrain, yTrain,epochs = theEpoch,batch_size = 256)


## @knitr predictModel 

results <- model %>% evaluate(xTest, yTest)
results
```

```{r eval=FALSE, include=FALSE}
yhat_keras_class_vec <- predict_classes(object = model, x = xTest) %>%
  as.vector()

yhat_keras_prob_vec  <- predict_proba(object = model, x = xTest) %>%
  as.vector()

estimates_keras_tbl <- tibble(
  truth      = as.factor(yTest) %>% fct_recode(yes = "1", no = "0"),
  estimate   = as.factor(yhat_keras_class_vec) %>% fct_recode(yes = "1", no = "0"),
  class_prob = yhat_keras_prob_vec
)

options(yardstick.event_first = FALSE)

estimates_keras_tbl %>% conf_mat(truth, estimate)

estimates_keras_tbl %>% metrics(truth, estimate)

## @knitr specificPredictions

theTestIndices <- c(313, 201)
cat(str_wrap(credit_card$`Consumer complaint narrative`[testIndex[theTestIndices[1]]],width=60))
cat(str_wrap(credit_card$`Consumer complaint narrative`[testIndex[theTestIndices[2]]],width=60))

model %>% predict(xTest[theTestIndices,])

```

